# PrevisÃ£o de Vendas de Produtos Amazon

<div align="center">

![Python](https://img.shields.io/badge/Python-3.12-blue)
![XGBoost](https://img.shields.io/badge/XGBoost-3.1.1-green)
![scikit-learn](https://img.shields.io/badge/scikit--learn-1.7.2-orange)
![License](https://img.shields.io/badge/license-MIT-blue)

**Projeto de Machine Learning para prever quantidade de produtos comprados no Ãºltimo mÃªs**

</div>

---

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um modelo de machine learning para prever a quantidade de produtos comprados no Ãºltimo mÃªs (`purchased_last_month`) utilizando dados de produtos da Amazon. O projeto utiliza **XGBoost** com hiperparÃ¢metros otimizados atravÃ©s de **RandomizedSearchCV** com validaÃ§Ã£o cruzada 5-fold.

### Objetivo

Desenvolver um modelo preditivo robusto que possa auxiliar em:

- ğŸ“¦ GestÃ£o de inventÃ¡rio
- ğŸ“Š Planejamento de demanda
- ğŸ’° EstratÃ©gias de pricing
- ğŸ¯ IdentificaÃ§Ã£o de produtos com alto potencial de vendas

---

## ğŸ¯ Resultados AlcanÃ§ados

| MÃ©trica                  | Valor    | DescriÃ§Ã£o                                    |
| ------------------------ | -------- | -------------------------------------------- |
| **RÂ² Score**             | 0.9133   | Modelo explica 91.33% da variÃ¢ncia nos dados |
| **RMSE**                 | 1,688.26 | Erro mÃ©dio quadrÃ¡tico                        |
| **MAE**                  | 338.99   | Erro absoluto mÃ©dio                          |
| **sMAPE**                | 56.91%   | Erro percentual simÃ©trico                    |
| **Melhoria vs Baseline** | 7.7%     | ReduÃ§Ã£o no RMSE apÃ³s tuning                  |

**Modelo Final:** XGBoost Otimizado com 19 features engineered

---

## ğŸ“Š Dataset

- **Fonte:** [Kaggle - Amazon Products Sales Dataset](https://www.kaggle.com/datasets/ikramshah512/amazon-products-sales-dataset-42k-items-2025)
- **Tamanho original:** 42,675 produtos
- **ApÃ³s limpeza:** 34,140 produtos
- **Features:** 19 features apÃ³s preprocessing e feature engineering
- **DivisÃ£o:** 80% treino / 20% teste

### Features Principais

- **NumÃ©ricas:** preÃ§o original, preÃ§o com desconto, rating, total de reviews
- **CategÃ³ricas:** categoria do produto, badges (Best Seller, Sponsored), cupons
- **Engineered:** discount_amount, price_ratio, rating_review_interaction, log_total_reviews

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python:** 3.12.12
- **Machine Learning:**
  - XGBoost 3.1.1
  - scikit-learn 1.7.2
  - scipy 1.16.3
- **Data Analysis:**
  - pandas 2.3.3
  - numpy 2.3.4
- **VisualizaÃ§Ã£o:**
  - matplotlib 3.10.7
  - seaborn 0.13.2
- **Ambiente:** conda (environment.yml fornecido)

---

## ğŸ“¦ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.12+
- conda (Anaconda ou Miniconda)
- Git (opcional, para clonar o repositÃ³rio)

### OpÃ§Ã£o 1: Usando Conda (Recomendado)

#### Windows

```bash
# 1. Clone o repositÃ³rio (ou baixe o ZIP)
git clone git@github.com:bathwaterpizza/data-science-25-2.git
cd data-science-25-2

# 2. Crie o ambiente conda
conda env create -f environment.yml

# 3. Ative o ambiente
conda activate dsproj

# 4. Verifique a instalaÃ§Ã£o
python --version
python -c "import xgboost; print(f'XGBoost {xgboost.__version__}')"
```

#### macOS

```bash
# 1. Clone o repositÃ³rio (ou baixe o ZIP)
git clone git@github.com:bathwaterpizza/data-science-25-2.git
cd data-science-25-2

# 2. Crie o ambiente conda
conda env create -f environment.yml

# 3. Ative o ambiente
conda activate dsproj

# 4. Verifique a instalaÃ§Ã£o
python --version
python -c "import xgboost; print(f'XGBoost {xgboost.__version__}')"
```

### OpÃ§Ã£o 2: Usando pip (Alternativa)

```bash
# 1. Crie um ambiente virtual
python -m venv venv

# 2. Ative o ambiente
# Windows:
venv\Scripts\activate
# macOS/Linux:
source venv/bin/activate

# 3. Instale as dependÃªncias
pip install pandas==2.3.3 numpy==2.3.4 scikit-learn==1.7.2 xgboost==3.1.1 matplotlib==3.10.7 seaborn==0.13.2 scipy==1.16.3 jupyterlab

# 4. Verifique a instalaÃ§Ã£o
python -c "import xgboost, sklearn; print('OK')"
```

---

## ğŸš€ Como Executar

### ExploraÃ§Ã£o e AnÃ¡lise (Notebooks Jupyter)

```bash
# Ative o ambiente
conda activate dsproj

# Inicie o JupyterLab
jupyter lab
```

**Ordem recomendada de execuÃ§Ã£o dos notebooks:**

1. `exploratory_data_analysis.ipynb` - AnÃ¡lise exploratÃ³ria dos dados
2. `phase1_preprocessing.ipynb` - Preprocessamento e feature engineering
3. `phase2_model_training.ipynb` - Treinamento de mÃºltiplos modelos
4. `phase3_model_evaluation.ipynb` - AvaliaÃ§Ã£o inicial dos modelos
5. `phase4_hyperparameter_tuning.ipynb` - OtimizaÃ§Ã£o do XGBoost
6. `phase5_improved_evaluation.ipynb` - AvaliaÃ§Ã£o com mÃ©tricas avanÃ§adas
7. `model_performance_report.ipynb` - **RelatÃ³rio final completo** â­

---

## ğŸ“ Estrutura do Projeto

```
data-science-25-2/
â”‚
â”œâ”€â”€ README.md                              # Este arquivo
â”œâ”€â”€ environment.yml                        # DependÃªncias conda
â”œâ”€â”€ .gitignore                            # Arquivos ignorados pelo git
â”‚
â”œâ”€â”€ amazon_products_sales_data_cleaned.csv # Dataset limpo
â”‚
â”œâ”€â”€ exploratory_data_analysis.ipynb       # Fase 0: EDA
â”œâ”€â”€ phase1_preprocessing.ipynb            # Fase 1: Preprocessamento
â”œâ”€â”€ phase2_model_training.ipynb           # Fase 2: Treinamento
â”œâ”€â”€ phase3_model_evaluation.ipynb         # Fase 3: AvaliaÃ§Ã£o inicial
â”œâ”€â”€ phase4_hyperparameter_tuning.ipynb    # Fase 4: Tuning
â”œâ”€â”€ phase5_improved_evaluation.ipynb      # Fase 5: MÃ©tricas avanÃ§adas
â”œâ”€â”€ model_performance_report.ipynb        # ğŸ“Š RelatÃ³rio Final
â”‚
â”œâ”€â”€ models/                                # Modelos treinados
â”‚   â”œâ”€â”€ xgboost_tuned.pkl                 # ğŸ† Modelo final
â”‚   â”œâ”€â”€ best_params.pkl                   # HiperparÃ¢metros otimizados
â”‚   â”œâ”€â”€ xgboost.pkl                       # Baseline
â”‚   â””â”€â”€ ... (outros modelos)
â”‚
â”œâ”€â”€ scaler.pkl                            # StandardScaler treinado
â”œâ”€â”€ feature_names.pkl                     # Nomes das features
â”‚
â”œâ”€â”€ X_train.csv, X_test.csv              # Dados de treino/teste
â”œâ”€â”€ y_train_original.csv, y_test_original.csv
â”‚
â”œâ”€â”€ model_comparison_results.csv          # Resultados comparativos
â”œâ”€â”€ tuning_comparison.csv                 # Baseline vs Tuned
â”œâ”€â”€ improved_metrics_results.csv          # MÃ©tricas avanÃ§adas
â”œâ”€â”€ stratified_performance.csv            # Performance por segmento
â”‚
â””â”€â”€ *.png                                 # VisualizaÃ§Ãµes geradas
```

---

## ğŸ“ˆ Pipeline do Projeto

```mermaid
graph LR
    A[Raw Data] --> B[EDA]
    B --> C[Preprocessing]
    C --> D[Feature Engineering]
    D --> E[Model Training]
    E --> F[Model Evaluation]
    F --> G[Hyperparameter Tuning]
    G --> H[Final Evaluation]
    H --> I[Production Model]
```

### Fases Detalhadas

1. **AnÃ¡lise ExploratÃ³ria (EDA)**

   - AnÃ¡lise de distribuiÃ§Ãµes
   - IdentificaÃ§Ã£o de outliers
   - AnÃ¡lise de correlaÃ§Ãµes
   - IdentificaÃ§Ã£o de missing values

2. **Preprocessamento**

   - Tratamento de missing values
   - RemoÃ§Ã£o de features irrelevantes
   - Encoding de variÃ¡veis categÃ³ricas
   - Feature engineering
   - Train/test split (80/20)

3. **Treinamento de Modelos**

   - Linear Regression
   - Ridge, Lasso, ElasticNet
   - Random Forest
   - XGBoost (melhor desempenho)
   - Gradient Boosting

4. **Hyperparameter Tuning**

   - RandomizedSearchCV
   - 5-fold cross-validation
   - 50 combinaÃ§Ãµes testadas
   - Melhoria de 7.7% no RMSE

5. **AvaliaÃ§Ã£o Final**
   - MÃ©tricas tradicionais: RMSE, MAE, RÂ²
   - MÃ©tricas avanÃ§adas: sMAPE, MdAPE
   - AnÃ¡lise estratificada por volume
   - Feature importance
   - Learning curves

---

## ğŸ” Detalhes TÃ©cnicos

### Preprocessamento

1. **Missing Values:**

   - Mediana para features numÃ©ricas
   - Flag binÃ¡ria para sustainability_tags
   - 'Unknown' para buy_box_availability

2. **Feature Engineering:**

   ```python
   discount_amount = original_price - discounted_price
   price_ratio = discounted_price / original_price
   rating_review_interaction = product_rating Ã— log(total_reviews)
   log_total_reviews = log1p(total_reviews)
   ```

3. **TransformaÃ§Ãµes:**
   - Log transformation para target (modelos lineares)
   - StandardScaler para features numÃ©ricas
   - One-hot encoding para categorias

### Modelo Final: XGBoost Tuned

**HiperparÃ¢metros Otimizados:**

- Ver arquivo `models/best_params.pkl` para detalhes completos
- Otimizado para minimizar RMSE
- RegularizaÃ§Ã£o L1 e L2 aplicadas

**Por que XGBoost?**

- âœ… Melhor performance entre todos os modelos
- âœ… Robusto a outliers
- âœ… Lida bem com features categÃ³ricas
- âœ… RegularizaÃ§Ã£o integrada previne overfitting
- âœ… Feature importance built-in

---

## ğŸ“Š VisualizaÃ§Ãµes e RelatÃ³rios

### RelatÃ³rio Principal

Execute o notebook `model_performance_report.ipynb` para gerar um relatÃ³rio completo em portuguÃªs com:

- ğŸ“ˆ ComparaÃ§Ã£o de todos os modelos
- ğŸ¯ Resultados do hyperparameter tuning
- ğŸ“Š MÃ©tricas avanÃ§adas (sMAPE, MdAPE)
- ğŸ” Feature importance
- ğŸ“‰ Learning curves
- ğŸ¨ AnÃ¡lise estratificada
- ğŸ“ Residual plots

### VisualizaÃ§Ãµes Geradas

- `model_comparison.png` - ComparaÃ§Ã£o inicial de modelos
- `learning_curves.png` - Curvas de aprendizado
- `feature_importance_tuned.png` - ImportÃ¢ncia das features
- `metrics_comparison.png` - ComparaÃ§Ã£o de mÃ©tricas
- E vÃ¡rias outras geradas ao executar os notebooks

---

## ğŸ“ Insights e Aprendizados

### Features Mais Importantes

1. InteraÃ§Ã£o entre rating e reviews
2. PreÃ§os e descontos
3. Categorias especÃ­ficas de produtos
4. Badges promocionais

### LimitaÃ§Ãµes Identificadas

- Erro percentual maior em produtos com baixo volume de vendas
- Trade-off entre RMSE e MAE apÃ³s tuning
- Missing data em sustainability_tags

### RecomendaÃ§Ãµes para ProduÃ§Ã£o

1. **Monitoramento:**

   - Acompanhar data drift
   - Retreinar trimestralmente
   - Validar performance continuamente

2. **Melhorias Futuras:**
   - Adicionar features de sazonalidade
   - Incorporar preÃ§os de concorrentes
   - Implementar SHAP values para explicabilidade
   - Modelos especÃ­ficos por categoria

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor:

1. FaÃ§a um fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/NovaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona NovaFeature'`)
4. Push para a branch (`git push origin feature/NovaFeature`)
5. Abra um Pull Request

---

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

---

## ğŸ‘¤ Autor

**Seu Nome**

- GitHub: [@bathwaterpizza](https://github.com/bathwaterpizza)
- RepositÃ³rio: [data-science-25-2](https://github.com/bathwaterpizza/data-science-25-2)

---

## ğŸ“ Contato e Suporte

- Para reportar bugs ou sugerir features, abra uma [issue](https://github.com/bathwaterpizza/data-science-25-2/issues)
- Para dÃºvidas sobre o projeto, consulte a documentaÃ§Ã£o nos notebooks

---

## ğŸ™ Agradecimentos

- Dataset fornecido por [Ikram Shah no Kaggle](https://www.kaggle.com/datasets/ikramshah512/amazon-products-sales-dataset-42k-items-2025)
- Comunidade de Machine Learning e Data Science
- Bibliotecas open-source: XGBoost, scikit-learn, pandas, numpy

---

<div align="center">

**â­ Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no repositÃ³rio! â­**

Made with â¤ï¸ and ğŸ

</div>
