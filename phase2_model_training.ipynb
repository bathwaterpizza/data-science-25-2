{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase 2: Model Training\n",
        "\n",
        "**Objective:** Train multiple regression models to predict `purchased_last_month`\n",
        "\n",
        "---\n",
        "\n",
        "## Models to Train:\n",
        "1. **Baseline:** Linear Regression\n",
        "2. **Linear Models:** Ridge, Lasso, ElasticNet\n",
        "3. **Tree-Based Models:** Random Forest, XGBoost, Gradient Boosting\n",
        "\n",
        "All models will be saved for evaluation in Phase 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import time\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Preprocessed Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully!\n",
            "\n",
            "X_train shape: (25731, 29)\n",
            "X_test shape: (6433, 29)\n",
            "y_train shape: (25731,)\n",
            "y_test shape: (6433,)\n"
          ]
        }
      ],
      "source": [
        "# Load scaled data (for linear models)\n",
        "X_train_scaled = pd.read_csv('X_train_scaled.csv')\n",
        "X_test_scaled = pd.read_csv('X_test_scaled.csv')\n",
        "\n",
        "# Load unscaled data (for tree-based models)\n",
        "X_train = pd.read_csv('X_train.csv')\n",
        "X_test = pd.read_csv('X_test.csv')\n",
        "\n",
        "# Load targets\n",
        "y_train_original = pd.read_csv('y_train_original.csv')['purchased_last_month']\n",
        "y_test_original = pd.read_csv('y_test_original.csv')['purchased_last_month']\n",
        "y_train_log = pd.read_csv('y_train_log.csv')['log_purchased_last_month']\n",
        "y_test_log = pd.read_csv('y_test_log.csv')['log_purchased_last_month']\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "print(f\"\\nX_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train_original.shape}\")\n",
        "print(f\"y_test shape: {y_test_original.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Define Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models will be trained with the following configurations:\n",
            "\n",
            "1. Linear Models (using scaled data + log-transformed target):\n",
            "   - Linear Regression\n",
            "   - Ridge Regression (alpha=1.0)\n",
            "   - Lasso Regression (alpha=1.0)\n",
            "   - ElasticNet (alpha=1.0, l1_ratio=0.5)\n",
            "\n",
            "2. Tree-Based Models (using unscaled data + original target):\n",
            "   - Random Forest (n_estimators=100, max_depth=20)\n",
            "   - XGBoost (n_estimators=100, max_depth=6, learning_rate=0.1)\n",
            "   - Gradient Boosting (n_estimators=100, max_depth=5, learning_rate=0.1)\n"
          ]
        }
      ],
      "source": [
        "# Dictionary to store all models\n",
        "models = {}\n",
        "training_times = {}\n",
        "\n",
        "print(\"Models will be trained with the following configurations:\")\n",
        "print(\"\\n1. Linear Models (using scaled data + log-transformed target):\")\n",
        "print(\"   - Linear Regression\")\n",
        "print(\"   - Ridge Regression (alpha=1.0)\")\n",
        "print(\"   - Lasso Regression (alpha=1.0)\")\n",
        "print(\"   - ElasticNet (alpha=1.0, l1_ratio=0.5)\")\n",
        "print(\"\\n2. Tree-Based Models (using unscaled data + original target):\")\n",
        "print(\"   - Random Forest (n_estimators=100, max_depth=20)\")\n",
        "print(\"   - XGBoost (n_estimators=100, max_depth=6, learning_rate=0.1)\")\n",
        "print(\"   - Gradient Boosting (n_estimators=100, max_depth=5, learning_rate=0.1)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Linear Models\n",
        "\n",
        "Linear models will use:\n",
        "- **Scaled features** (X_train_scaled)\n",
        "- **Log-transformed target** (y_train_log) - better for handling skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "TRAINING LINEAR MODELS\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 60)\n",
        "print(\"TRAINING LINEAR MODELS\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Linear Regression (Baseline)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[1/7] Training Linear Regression...\n",
            "✓ Linear Regression trained in 0.03 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[1/7] Training Linear Regression...\")\n",
        "start_time = time.time()\n",
        "\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_scaled, y_train_log)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "models['linear_regression'] = lr\n",
        "training_times['linear_regression'] = training_time\n",
        "\n",
        "print(f\"✓ Linear Regression trained in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Ridge Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[2/7] Training Ridge Regression...\n",
            "✓ Ridge Regression trained in 0.01 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[2/7] Training Ridge Regression...\")\n",
        "start_time = time.time()\n",
        "\n",
        "ridge = Ridge(alpha=1.0, random_state=42)\n",
        "ridge.fit(X_train_scaled, y_train_log)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "models['ridge'] = ridge\n",
        "training_times['ridge'] = training_time\n",
        "\n",
        "print(f\"✓ Ridge Regression trained in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[3/7] Training Lasso Regression...\n",
            "✓ Lasso Regression trained in 0.01 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[3/7] Training Lasso Regression...\")\n",
        "start_time = time.time()\n",
        "\n",
        "lasso = Lasso(alpha=1.0, random_state=42, max_iter=10000)\n",
        "lasso.fit(X_train_scaled, y_train_log)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "models['lasso'] = lasso\n",
        "training_times['lasso'] = training_time\n",
        "\n",
        "print(f\"✓ Lasso Regression trained in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4 ElasticNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[4/7] Training ElasticNet...\n",
            "✓ ElasticNet trained in 0.01 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[4/7] Training ElasticNet...\")\n",
        "start_time = time.time()\n",
        "\n",
        "elasticnet = ElasticNet(alpha=1.0, l1_ratio=0.5, random_state=42, max_iter=10000)\n",
        "elasticnet.fit(X_train_scaled, y_train_log)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "models['elasticnet'] = elasticnet\n",
        "training_times['elasticnet'] = training_time\n",
        "\n",
        "print(f\"✓ ElasticNet trained in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Tree-Based Models\n",
        "\n",
        "Tree-based models will use:\n",
        "- **Unscaled features** (X_train) - trees don't require scaling\n",
        "- **Original target** (y_train_original) - trees handle outliers well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING TREE-BASED MODELS\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING TREE-BASED MODELS\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[5/7] Training Random Forest...\n",
            "✓ Random Forest trained in 0.92 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[5/7] Training Random Forest...\")\n",
        "start_time = time.time()\n",
        "\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=20,\n",
        "    min_samples_split=5,\n",
        "    min_samples_leaf=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=0\n",
        ")\n",
        "rf.fit(X_train, y_train_original)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "models['random_forest'] = rf\n",
        "training_times['random_forest'] = training_time\n",
        "\n",
        "print(f\"✓ Random Forest trained in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[6/7] Training XGBoost...\n",
            "✓ XGBoost trained in 0.14 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[6/7] Training XGBoost...\")\n",
        "start_time = time.time()\n",
        "\n",
        "xgb = XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbosity=0\n",
        ")\n",
        "xgb.fit(X_train, y_train_original)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "models['xgboost'] = xgb\n",
        "training_times['xgboost'] = training_time\n",
        "\n",
        "print(f\"✓ XGBoost trained in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[7/7] Training Gradient Boosting...\n",
            "✓ Gradient Boosting trained in 2.61 seconds\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[7/7] Training Gradient Boosting...\")\n",
        "start_time = time.time()\n",
        "\n",
        "gb = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    subsample=0.8,\n",
        "    random_state=42,\n",
        "    verbose=0\n",
        ")\n",
        "gb.fit(X_train, y_train_original)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "models['gradient_boosting'] = gb\n",
        "training_times['gradient_boosting'] = training_time\n",
        "\n",
        "print(f\"✓ Gradient Boosting trained in {training_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Save All Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "SAVING MODELS\n",
            "============================================================\n",
            "✓ Saved: models/linear_regression.pkl\n",
            "✓ Saved: models/ridge.pkl\n",
            "✓ Saved: models/lasso.pkl\n",
            "✓ Saved: models/elasticnet.pkl\n",
            "✓ Saved: models/random_forest.pkl\n",
            "✓ Saved: models/xgboost.pkl\n",
            "✓ Saved: models/gradient_boosting.pkl\n",
            "✓ Saved: models/training_times.pkl\n",
            "✓ Saved: models/model_metadata.pkl\n",
            "\n",
            "✓ All models saved successfully!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Create a directory for models if it doesn't exist\n",
        "import os\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# Save each model\n",
        "for model_name, model in models.items():\n",
        "    filename = f'models/{model_name}.pkl'\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "    print(f\"✓ Saved: {filename}\")\n",
        "\n",
        "# Save training times\n",
        "with open('models/training_times.pkl', 'wb') as f:\n",
        "    pickle.dump(training_times, f)\n",
        "print(f\"✓ Saved: models/training_times.pkl\")\n",
        "\n",
        "# Save model metadata (which models use which data)\n",
        "model_metadata = {\n",
        "    'linear_models': ['linear_regression', 'ridge', 'lasso', 'elasticnet'],\n",
        "    'tree_models': ['random_forest', 'xgboost', 'gradient_boosting'],\n",
        "    'uses_scaled_data': ['linear_regression', 'ridge', 'lasso', 'elasticnet'],\n",
        "    'uses_log_target': ['linear_regression', 'ridge', 'lasso', 'elasticnet']\n",
        "}\n",
        "\n",
        "with open('models/model_metadata.pkl', 'wb') as f:\n",
        "    pickle.dump(model_metadata, f)\n",
        "print(f\"✓ Saved: models/model_metadata.pkl\")\n",
        "\n",
        "print(\"\\n✓ All models saved successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Training Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "TRAINING SUMMARY\n",
            "============================================================\n",
            "\n",
            "Total models trained: 7\n",
            "\n",
            "Training times:\n",
            "  lasso               :   0.01 seconds\n",
            "  ridge               :   0.01 seconds\n",
            "  elasticnet          :   0.01 seconds\n",
            "  linear_regression   :   0.03 seconds\n",
            "  xgboost             :   0.14 seconds\n",
            "  random_forest       :   0.92 seconds\n",
            "  gradient_boosting   :   2.61 seconds\n",
            "\n",
            "Total training time: 3.72 seconds\n",
            "\n",
            "============================================================\n",
            "Models saved in ./models/ directory:\n",
            "============================================================\n",
            "  ✓ models/linear_regression.pkl\n",
            "  ✓ models/ridge.pkl\n",
            "  ✓ models/lasso.pkl\n",
            "  ✓ models/elasticnet.pkl\n",
            "  ✓ models/random_forest.pkl\n",
            "  ✓ models/xgboost.pkl\n",
            "  ✓ models/gradient_boosting.pkl\n",
            "\n",
            "============================================================\n",
            "READY FOR PHASE 3: MODEL EVALUATION\n",
            "============================================================\n",
            "\n",
            "All models have been trained and saved.\n",
            "Proceed to Phase 3 to evaluate their performance!\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"TRAINING SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"\\nTotal models trained: {len(models)}\")\n",
        "print(f\"\\nTraining times:\")\n",
        "for model_name, train_time in sorted(training_times.items(), key=lambda x: x[1]):\n",
        "    print(f\"  {model_name:20s}: {train_time:6.2f} seconds\")\n",
        "\n",
        "print(f\"\\nTotal training time: {sum(training_times.values()):.2f} seconds\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Models saved in ./models/ directory:\")\n",
        "print(\"=\" * 60)\n",
        "for model_name in models.keys():\n",
        "    print(f\"  ✓ models/{model_name}.pkl\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"READY FOR PHASE 3: MODEL EVALUATION\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll models have been trained and saved.\")\n",
        "print(\"Proceed to Phase 3 to evaluate their performance!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "Proceed to **Phase 3: Model Evaluation** to:\n",
        "- Load all trained models\n",
        "- Make predictions on test set\n",
        "- Calculate performance metrics (RMSE, MAE, R², MAPE)\n",
        "- Compare all models\n",
        "- Visualize results\n",
        "- Select the best model"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (dsproj)",
      "language": "python",
      "name": "dsproj"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
