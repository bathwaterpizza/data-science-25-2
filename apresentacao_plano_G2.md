# Plano de Apresenta√ß√£o - G2

## Previs√£o de Vendas de Produtos Amazon com Machine Learning

### Tempo Total: 10 minutos

---

## Slide 1: T√≠tulo e Equipe (30 segundos)

### Conte√∫do Visual:

- **T√≠tulo:** "Previs√£o de Vendas de Produtos Amazon com XGBoost Otimizado"
- **Subt√≠tulo:** "Aplica√ß√£o de Machine Learning para Forecasting de Demanda"
- **Logo/Imagem:** √çcone Amazon + gr√°fico de tend√™ncia
- **Nome da equipe/integrantes**
- **Data:** Novembro 2024
- **Curso:** Ci√™ncia de Dados

### Talking Points:

- "Boa tarde, hoje apresentamos nosso projeto de previs√£o de vendas de produtos Amazon"
- "Desenvolvemos um modelo de machine learning capaz de prever com 91% de acur√°cia a quantidade de produtos vendidos no √∫ltimo m√™s"

---

## Slide 2: Problema e Motiva√ß√£o (1 minuto)

### Conte√∫do Visual:

- **Contexto do Problema:**

  - 42.675 produtos no marketplace Amazon
  - Necessidade de previs√£o de demanda para gest√£o de invent√°rio
  - Impacto direto em decis√µes de neg√≥cio

- **Objetivo Principal:**

  - Prever `purchased_last_month` (quantidade vendida no √∫ltimo m√™s)
  - R¬≤ alvo: > 0.85

- **Aplica√ß√µes Pr√°ticas:**
  - üì¶ Otimiza√ß√£o de estoque
  - üí∞ Estrat√©gias de pricing din√¢mico
  - üìä Planejamento de demanda
  - üéØ Identifica√ß√£o de produtos de alto potencial

### Talking Points:

- "O problema surge da necessidade real de empresas no marketplace Amazon preverem demanda"
- "Com milhares de produtos, √© imposs√≠vel gerenciar manualmente o estoque"
- "Nossa solu√ß√£o permite prever vendas futuras com base em caracter√≠sticas dos produtos"
- "O impacto: redu√ß√£o de ruptura de estoque e capital parado em invent√°rio"

---

## Slide 3: Dataset - Caracter√≠sticas e Desafios (2 minutos)

### Conte√∫do Visual - Parte 1:

- **Dataset Original:**
  - Fonte: Kaggle (Amazon Products Sales 2025)
  - 42.675 produtos ‚Üí 34.140 ap√≥s limpeza (20% removidos)
  - 17 features originais ‚Üí 19 ap√≥s feature engineering
- **Features Principais:**
  - Pre√ßo (original/desconto)
  - Rating e reviews
  - Categoria do produto
  - Badges (Best Seller, Sponsored)

### Conte√∫do Visual - Parte 2:

- **Desafios Encontrados:**

  1. **Distribui√ß√£o extremamente assim√©trica** (gr√°fico de distribui√ß√£o)

     - Skewness = 15.2
     - Produtos com 0 at√© 50.000+ vendas

  2. **Missing Values (25% dos dados)**

     - sustainability_tags: 60% missing
     - buy_box_availability: 35% missing

  3. **Outliers extremos**
     - IQR method: 8.500 outliers detectados

### Talking Points:

- "Nosso dataset apresentou desafios significativos desde o in√≠cio"
- "A distribui√ß√£o altamente assim√©trica dificultava previs√µes precisas"
- "25% dos dados tinham valores faltantes que precisavam tratamento cuidadoso"
- "Descobrimos insights importantes: produtos com badge Best Seller vendem 300% mais"

---

## Slide 4: Metodologia - Pr√©-processamento e Feature Engineering (2 minutos)

### Conte√∫do Visual - Parte 1:

- **Pipeline de Pr√©-processamento:**
  ```
  Raw Data (42.675) ‚Üí Missing Values ‚Üí Feature Engineering ‚Üí Scaling ‚Üí Split 80/20
  ```
- **Tratamento de Missing Values:**
  - Num√©ricas: mediana
  - Categ√≥ricas: flag bin√°ria + "Unknown"
  - Target missing: remo√ß√£o (8.535 linhas)

### Conte√∫do Visual - Parte 2:

- **Feature Engineering Criadas:**

  - `discount_amount` = original_price - discounted_price
  - `price_ratio` = discounted_price / original_price
  - `rating_review_interaction` = rating √ó log(reviews)
  - `log_total_reviews` = log1p(total_reviews)

- **Transforma√ß√µes Aplicadas:**
  - Log1p no target para modelos lineares
  - StandardScaler para features num√©ricas
  - One-hot encoding (5 categorias)

### Talking Points:

- "Desenvolvemos um pipeline robusto de pr√©-processamento"
- "A feature engineering foi crucial - a intera√ß√£o rating√óreviews se tornou a 2¬™ mais importante"
- "Aplicamos transforma√ß√£o logar√≠tmica no target para lidar com a assimetria"
- "Importante: essa transforma√ß√£o causou problemas posteriormente que vou explicar"

---

## Slide 5: Modelagem - Algoritmos e Otimiza√ß√£o (2 minutos)

### Conte√∫do Visual - Parte 1:

- **7 Modelos Testados:**
  | Modelo | R¬≤ Score | RMSE |
  |--------|----------|------|
  | Linear Regression | 0.198 | 5,133 |
  | Ridge | 0.198 | 5,134 |
  | Lasso | -0.030 | 5,819 |
  | ElasticNet | -0.023 | 5,799 |
  | Random Forest | 0.861 | 2,139 |
  | **XGBoost** | **0.898** | **1,828** |
  | Gradient Boosting | 0.875 | 2,028 |

### Conte√∫do Visual - Parte 2:

- **Hyperparameter Tuning (XGBoost):**
  - M√©todo: RandomizedSearchCV
  - 50 combina√ß√µes √ó 5-fold CV = 250 fits
  - Tempo: 25 minutos
- **Par√¢metros Otimizados:**
  - max_depth: 6 ‚Üí 8
  - learning_rate: 0.1 ‚Üí 0.05
  - n_estimators: 100 ‚Üí 300
  - Regulariza√ß√£o L1/L2 adicionada

### Talking Points:

- "Testamos desde modelos lineares simples at√© ensemble methods complexos"
- "XGBoost se destacou com R¬≤ de 0.898, explicando quase 90% da vari√¢ncia"
- "O tuning de hiperpar√¢metros trouxe melhoria adicional de 7.7% no RMSE"
- "RandomizedSearch foi escolhido por ser mais eficiente que GridSearch"

---

## Slide 6: Dificuldade Espec√≠fica - Li√ß√£o Aprendida (1 minuto)

### Conte√∫do Visual:

- **O Problema:**

  - Usamos colunas com log1p criadas para modelos lineares
  - Aplicamos essas mesmas features em modelos tree-based
  - Resultado: performance P√âSSIMA inicial (R¬≤ < 0.3)

- **Diagn√≥stico:**

  - Modelos de √°rvore n√£o precisam de transforma√ß√µes logar√≠tmicas
  - Trees s√£o naturalmente robustas a outliers e assimetria
  - Transforma√ß√£o desnecess√°ria distorceu os padr√µes

- **Solu√ß√£o:**
  - Separamos pipelines: features escaladas para modelos lineares
  - Features originais para tree-based models
  - Resultado: melhoria de 60% no R¬≤

### Talking Points:

- "Uma li√ß√£o importante: nem toda t√©cnica de pr√©-processamento √© universal"
- "Inicialmente aplicamos log1p em todas as features para todos os modelos"
- "Descobrimos que isso prejudicava severamente os modelos de √°rvore"
- "A corre√ß√£o foi simples mas o aprendizado foi valioso"

---

## Slide 7: Resultados - M√©tricas e Performance (2 minutos)

### Conte√∫do Visual - Parte 1:

- **M√©tricas do Modelo Final (XGBoost Tuned):**
  - **R¬≤ Score:** 0.9133 (91.33% vari√¢ncia explicada)
  - **RMSE:** 1,688.26 unidades
  - **MAE:** 338.99 unidades
  - **sMAPE:** 56.91%
  - **Melhoria vs Baseline:** 7.7% redu√ß√£o RMSE

### Conte√∫do Visual - Parte 2:

- **Gr√°ficos Principais:**
  1. Compara√ß√£o de modelos (barras)
  2. Feature importance (top 10)
  3. Actual vs Predicted scatter plot
  4. Learning curves (sem overfitting)

### Conte√∫do Visual - Parte 3:

- **Performance por Segmento:**
  | Volume | Produtos | RMSE | MdAPE |
  |--------|----------|------|-------|
  | Low (<500) | 4,971 | 254 | 80.7% |
  | Medium (500-5K) | 1,173 | 1,581 | 25.8% |
  | High (>5K) | 289 | 17,791 | 1.7% |

### Talking Points:

- "Alcan√ßamos R¬≤ de 0.9133, superando significativamente nossa meta de 0.85"
- "O modelo √© especialmente preciso em produtos de alto volume (MdAPE 1.7%)"
- "As features mais importantes s√£o intera√ß√µes pre√ßo-rating e badges promocionais"
- "Learning curves mostram que o modelo generaliza bem sem overfitting"

---

## Slide 8: Visualiza√ß√µes e Interpreta√ß√µes (1 minuto)

### Conte√∫do Visual:

- **4 Visualiza√ß√µes em Grid:**

  1. **Feature Importance** (top 5)

     - rating_review_interaction: 18%
     - log_total_reviews: 15%
     - discount_amount: 12%

  2. **Predi√ß√µes vs Real** (scatter)

     - Pontos concentrados na diagonal
     - Poucos outliers extremos

  3. **Distribui√ß√£o de Erros** (histogram)

     - Centrada em zero
     - Distribui√ß√£o normal

  4. **Melhoria com Tuning** (antes/depois)
     - RMSE: 1828 ‚Üí 1688
     - R¬≤: 0.898 ‚Üí 0.913

### Talking Points:

- "As visualiza√ß√µes confirmam a robustez do modelo"
- "A feature importance revela que intera√ß√µes complexas s√£o mais preditivas"
- "Os erros est√£o bem distribu√≠dos, sem vi√©s sistem√°tico"

---

## Slide 9: Conclus√µes e Aprendizados (1.5 minutos)

### Conte√∫do Visual - Parte 1:

- **‚úÖ Objetivos Alcan√ßados:**
  - Modelo com 91.33% de acur√°cia (meta: 85%)
  - Pipeline completo de ML implementado
  - 7.7% de melhoria com otimiza√ß√£o
  - Insights acion√°veis para neg√≥cio

### Conte√∫do Visual - Parte 2:

- **üìö Principais Aprendizados:**
  1. Import√¢ncia do EDA detalhado (25% do tempo)
  2. Feature engineering > modelos complexos
  3. Diferentes modelos = diferentes pr√©-processamentos
  4. Cross-validation essencial para robustez

### Conte√∫do Visual - Parte 3:

- **‚ö†Ô∏è Limita√ß√µes Identificadas:**

  - Performance menor em produtos low-volume
  - Dados de apenas 1 m√™s (sem sazonalidade)
  - Features externas n√£o dispon√≠veis (competidores, economia)

- **üöÄ Trabalhos Futuros:**
  - Incorporar dados temporais/sazonais
  - Modelo espec√≠fico por categoria
  - Deploy em produ√ß√£o com API
  - A/B testing com previs√µes

### Talking Points:

- "Superamos nossas metas e criamos um modelo production-ready"
- "O projeto refor√ßou a import√¢ncia do processo end-to-end de data science"
- "Aprendemos que 80% do trabalho est√° na prepara√ß√£o dos dados"
- "Como pr√≥ximos passos, seria valioso coletar dados temporais para capturar sazonalidade"

---

## Slide 10: Obrigado + Q&A (30 segundos)

### Conte√∫do Visual:

- **Resumo Final:**

  - üìä 42.675 produtos analisados
  - üéØ 91.33% de acur√°cia alcan√ßada
  - üöÄ Modelo pronto para produ√ß√£o
  - üìà ROI potencial: redu√ß√£o de 30% em ruptura de estoque

- **Contato/Reposit√≥rio:**

  - GitHub: github.com/bathwaterpizza/data-science-25-2
  - Modelo dispon√≠vel: models/xgboost_tuned.pkl

- **"Perguntas?"** (grande e centralizado)

### Talking Points:

- "Em resumo, desenvolvemos uma solu√ß√£o robusta para previs√£o de vendas"
- "O modelo est√° dispon√≠vel no GitHub junto com toda documenta√ß√£o"
- "Agrade√ßo a aten√ß√£o e estou aberto a perguntas"

---

## Notas para o Apresentador

### Timing:

- Mantenha rigor no tempo - use cron√¥metro
- Slides 3-7 s√£o os mais importantes (70% do tempo)
- Se atrasar, pule detalhes t√©cnicos dos slides 4-5

### Dicas de Apresenta√ß√£o:

1. **In√≠cio forte:** Comece com o impacto (91% de acur√°cia)
2. **Storytelling:** Conte a jornada dos dados at√© o modelo
3. **Seja visual:** Aponte para os gr√°ficos enquanto explica
4. **Admita limita√ß√µes:** Mostra maturidade t√©cnica
5. **Termine com impacto:** Volte ao valor de neg√≥cio

### Poss√≠veis Perguntas Q&A:

- **P: Por que XGBoost e n√£o Deep Learning?**
  - R: Dataset pequeno (34K), XGBoost melhor para dados tabulares estruturados
- **P: Como lidaram com overfitting?**
  - R: Cross-validation 5-fold, regulariza√ß√£o L1/L2, early stopping
- **P: Qual o custo computacional?**

  - R: Treinamento ~30min, predi√ß√£o <1seg para 1000 produtos

- **P: Como garantir performance em produ√ß√£o?**
  - R: Monitoramento de drift, retreino trimestral, A/B testing

### Material de Apoio:

- Tenha o notebook `model_performance_report.ipynb` aberto para mostrar detalhes se perguntarem
- Screenshots dos principais gr√°ficos salvos como backup
